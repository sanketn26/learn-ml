{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 ‚Äî LangGraph Fundamentals & State Management\n",
    "\n",
    "**Course:** LangGraph for Complex Workflows  \n",
    "**Week Focus:** Master state graphs, conditional routing, and multi-step workflows to build production-grade AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this week, you will:\n",
    "- Understand why graphs are superior to linear chains for complex workflows\n",
    "- Design and implement StateGraph with typed state schemas\n",
    "- Build nodes (workflow steps) and edges (transitions)\n",
    "- Implement conditional routing based on state\n",
    "- Handle errors gracefully in graph execution\n",
    "- Visualize and debug graph workflows\n",
    "- Build a real-world document processing pipeline\n",
    "\n",
    "## üìä Real-World Context\n",
    "\n",
    "**The Challenge:** Your content platform receives 10,000+ user submissions daily:\n",
    "- üìÑ Blog posts, comments, product reviews\n",
    "- üé≠ Mix of legitimate content and spam/toxic material\n",
    "- üåç Multiple languages requiring classification\n",
    "- ‚öñÔ∏è Need to moderate without human bottleneck\n",
    "\n",
    "**Linear Chain Limitations:**\n",
    "```python\n",
    "# ‚ùå This doesn't work well:\n",
    "chain = classify | moderate | summarize | publish\n",
    "# Problem: What if we need to:\n",
    "# - Route spam to deletion (skip summarization)\n",
    "# - Send toxic content to human review\n",
    "# - Handle multiple languages differently\n",
    "# - Retry failed steps\n",
    "```\n",
    "\n",
    "**The Solution:** A content moderation graph that:\n",
    "1. **Classifies** content type (article/comment/review/spam)\n",
    "2. **Detects** language and toxicity\n",
    "3. **Routes** based on results:\n",
    "   - Spam ‚Üí Auto-reject\n",
    "   - Toxic ‚Üí Human review queue\n",
    "   - Clean ‚Üí Extract key info\n",
    "4. **Summarizes** approved content\n",
    "5. **Publishes** or routes for approval\n",
    "\n",
    "**Business Impact:**\n",
    "- üöÄ Process 10K submissions/day (up from 500 manual reviews)\n",
    "- ‚è±Ô∏è Reduce moderation time from 4 hours ‚Üí 2 minutes\n",
    "- üéØ 95% accuracy with 10% human review (high-risk items)\n",
    "- üí∞ Save $240K/year in moderation costs\n",
    "\n",
    "Companies like **Reddit, Medium, and Substack** use similar graph-based moderation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "<style>\n",
    ".jp-RenderedHTMLCommon h2 {\n",
    "    color: #2c3e50;\n",
    "    border-bottom: 2px solid #3498db;\n",
    "    padding-bottom: 10px;\n",
    "    margin-top: 30px;\n",
    "}\n",
    ".jp-RenderedHTMLCommon h3 {\n",
    "    color: #34495e;\n",
    "    margin-top: 20px;\n",
    "}\n",
    ".jp-RenderedHTMLCommon code {\n",
    "    background-color: #f8f9fa;\n",
    "    padding: 2px 6px;\n",
    "    border-radius: 3px;\n",
    "    font-family: 'Courier New', monospace;\n",
    "}\n",
    ".jp-RenderedHTMLCommon pre {\n",
    "    background-color: #f8f9fa;\n",
    "    border-left: 4px solid #3498db;\n",
    "    padding: 15px;\n",
    "    border-radius: 5px;\n",
    "}\n",
    ".exercise-box {\n",
    "    background-color: #fff3cd;\n",
    "    border-left: 5px solid #ffc107;\n",
    "    padding: 15px;\n",
    "    margin: 20px 0;\n",
    "    border-radius: 5px;\n",
    "}\n",
    ".scenario-box {\n",
    "    background-color: #d1ecf1;\n",
    "    border-left: 5px solid #17a2b8;\n",
    "    padding: 15px;\n",
    "    margin: 20px 0;\n",
    "    border-radius: 5px;\n",
    "}\n",
    ".graph-box {\n",
    "    background-color: #e7f3e7;\n",
    "    border-left: 5px solid #28a745;\n",
    "    padding: 15px;\n",
    "    margin: 20px 0;\n",
    "    border-radius: 5px;\n",
    "    font-family: monospace;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Part 1: Why Graphs? (Linear Chains vs State Graphs)\n",
    "\n",
    "### The Problem with Linear Chains\n",
    "\n",
    "LangChain chains work great for simple workflows, but fail for complex scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Linear Chain - Can't handle branching logic\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"‚ùå LINEAR CHAIN LIMITATIONS:\")\n",
    "print()\n",
    "\n",
    "# Example: Content moderation\n",
    "prompt = ChatPromptTemplate.from_template(\"Moderate this content: {content}\")\n",
    "llm = FakeListLLM(responses=[\"Content is spam\"])\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "print(\"Problem 1: No conditional routing\")\n",
    "print(\"  If content is spam, we should STOP here.\")\n",
    "print(\"  But chains always run ALL steps.\")\n",
    "print()\n",
    "\n",
    "print(\"Problem 2: No shared state\")\n",
    "print(\"  Each step only sees the previous output.\")\n",
    "print(\"  Can't access original input or intermediate results.\")\n",
    "print()\n",
    "\n",
    "print(\"Problem 3: No cycles/loops\")\n",
    "print(\"  Can't retry failed steps.\")\n",
    "print(\"  Can't implement 'try again until success' logic.\")\n",
    "print()\n",
    "\n",
    "print(\"Problem 4: Hard to debug\")\n",
    "print(\"  Can't inspect state between steps.\")\n",
    "print(\"  Can't visualize the workflow.\")\n",
    "print()\n",
    "\n",
    "print(\"üí° Solution: Use LangGraph!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LangGraph Way (State Graphs)\n",
    "\n",
    "LangGraph introduces:\n",
    "1. **State**: Shared context accessible by all nodes\n",
    "2. **Nodes**: Functions that read/write state\n",
    "3. **Conditional Edges**: Dynamic routing based on state\n",
    "4. **Cycles**: Loops and retries\n",
    "5. **Visualization**: See your workflow as a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ State Graph - Handles complexity elegantly\n",
    "\n",
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# 1. Define State Schema\n",
    "class ContentState(TypedDict):\n",
    "    \"\"\"Shared state across all nodes.\"\"\"\n",
    "    content: str\n",
    "    content_type: str  # \"spam\", \"toxic\", \"clean\"\n",
    "    decision: str       # \"reject\", \"review\", \"approve\"\n",
    "    summary: str\n",
    "\n",
    "# 2. Define Node Functions\n",
    "def classify_content(state: ContentState) -> ContentState:\n",
    "    \"\"\"Node 1: Classify content.\"\"\"\n",
    "    # In real app: use LLM to classify\n",
    "    if \"buy now\" in state[\"content\"].lower():\n",
    "        state[\"content_type\"] = \"spam\"\n",
    "    elif \"hate\" in state[\"content\"].lower():\n",
    "        state[\"content_type\"] = \"toxic\"\n",
    "    else:\n",
    "        state[\"content_type\"] = \"clean\"\n",
    "    return state\n",
    "\n",
    "def route_decision(state: ContentState) -> Literal[\"reject\", \"review\", \"approve\"]:\n",
    "    \"\"\"Conditional router: decide next step based on state.\"\"\"\n",
    "    if state[\"content_type\"] == \"spam\":\n",
    "        return \"reject\"\n",
    "    elif state[\"content_type\"] == \"toxic\":\n",
    "        return \"review\"\n",
    "    else:\n",
    "        return \"approve\"\n",
    "\n",
    "def reject_content(state: ContentState) -> ContentState:\n",
    "    \"\"\"Node 2a: Auto-reject spam.\"\"\"\n",
    "    state[\"decision\"] = \"rejected\"\n",
    "    state[\"summary\"] = \"Spam detected - auto-rejected\"\n",
    "    return state\n",
    "\n",
    "def queue_for_review(state: ContentState) -> ContentState:\n",
    "    \"\"\"Node 2b: Queue for human review.\"\"\"\n",
    "    state[\"decision\"] = \"needs_review\"\n",
    "    state[\"summary\"] = \"Toxic content - queued for human review\"\n",
    "    return state\n",
    "\n",
    "def approve_content(state: ContentState) -> ContentState:\n",
    "    \"\"\"Node 2c: Auto-approve clean content.\"\"\"\n",
    "    state[\"decision\"] = \"approved\"\n",
    "    state[\"summary\"] = \"Clean content - approved for publication\"\n",
    "    return state\n",
    "\n",
    "# 3. Build the Graph\n",
    "workflow = StateGraph(ContentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"classify\", classify_content)\n",
    "workflow.add_node(\"reject\", reject_content)\n",
    "workflow.add_node(\"review\", queue_for_review)\n",
    "workflow.add_node(\"approve\", approve_content)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"classify\")\n",
    "\n",
    "# Add conditional edges (routing logic)\n",
    "workflow.add_conditional_edges(\n",
    "    \"classify\",\n",
    "    route_decision,\n",
    "    {\n",
    "        \"reject\": \"reject\",\n",
    "        \"review\": \"review\",\n",
    "        \"approve\": \"approve\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# All paths end after their respective actions\n",
    "workflow.add_edge(\"reject\", END)\n",
    "workflow.add_edge(\"review\", END)\n",
    "workflow.add_edge(\"approve\", END)\n",
    "\n",
    "# 4. Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Graph created successfully!\")\n",
    "print(\"\\nüìä GRAPH STRUCTURE:\")\n",
    "print(\"\"\"\n",
    "    START\n",
    "      |\n",
    "      v\n",
    "  [classify]\n",
    "      |\n",
    "   <router>\n",
    "   /  |  \\\\\n",
    "  /   |   \\\\\n",
    "spam toxic clean\n",
    " |    |     |\n",
    " v    v     v\n",
    "[reject] [review] [approve]\n",
    " |    |     |\n",
    " v    v     v\n",
    "    END\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Graph with Different Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Spam content\n",
    "print(\"üß™ TEST 1: Spam Content\")\n",
    "print(\"=\" * 60)\n",
    "result1 = app.invoke({\"content\": \"BUY NOW! Limited time offer!!!\"})\n",
    "print(f\"Input: {result1['content']}\")\n",
    "print(f\"Type: {result1['content_type']}\")\n",
    "print(f\"Decision: {result1['decision']}\")\n",
    "print(f\"Summary: {result1['summary']}\")\n",
    "print()\n",
    "\n",
    "# Test 2: Toxic content\n",
    "print(\"üß™ TEST 2: Toxic Content\")\n",
    "print(\"=\" * 60)\n",
    "result2 = app.invoke({\"content\": \"I hate this product and everyone who uses it!\"})\n",
    "print(f\"Input: {result2['content']}\")\n",
    "print(f\"Type: {result2['content_type']}\")\n",
    "print(f\"Decision: {result2['decision']}\")\n",
    "print(f\"Summary: {result2['summary']}\")\n",
    "print()\n",
    "\n",
    "# Test 3: Clean content\n",
    "print(\"üß™ TEST 3: Clean Content\")\n",
    "print(\"=\" * 60)\n",
    "result3 = app.invoke({\"content\": \"This is a helpful tutorial on Python programming.\"})\n",
    "print(f\"Input: {result3['content']}\")\n",
    "print(f\"Type: {result3['content_type']}\")\n",
    "print(f\"Decision: {result3['decision']}\")\n",
    "print(f\"Summary: {result3['summary']}\")\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ Notice how each input takes a DIFFERENT path through the graph!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Part 2: Core Concepts Deep Dive\n",
    "\n",
    "### 2.1 State Schemas ‚Äî The Heart of LangGraph\n",
    "\n",
    "**State** is a shared dictionary that flows through the graph. Every node can:\n",
    "- **Read** from state\n",
    "- **Write** to state (updates are merged)\n",
    "- **Access** full history\n",
    "\n",
    "**Best Practices:**\n",
    "1. Use TypedDict for type safety\n",
    "2. Document each field\n",
    "3. Keep state flat (avoid deep nesting)\n",
    "4. Use Optional for fields set later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, List\n",
    "from datetime import datetime\n",
    "\n",
    "# ‚úÖ Good State Design\n",
    "class DocumentProcessingState(TypedDict):\n",
    "    \"\"\"State for multi-step document processing workflow.\"\"\"\n",
    "    \n",
    "    # Input (set at start)\n",
    "    document_text: str\n",
    "    document_id: str\n",
    "    \n",
    "    # Classification results (set by classify node)\n",
    "    document_type: Optional[str]  # \"invoice\", \"contract\", \"report\"\n",
    "    language: Optional[str]        # \"en\", \"es\", \"fr\"\n",
    "    confidence: Optional[float]    # 0.0-1.0\n",
    "    \n",
    "    # Extraction results (set by extract node)\n",
    "    entities: Optional[List[dict]]  # [{\"type\": \"person\", \"value\": \"John\"}]\n",
    "    key_dates: Optional[List[str]]  # [\"2024-01-15\", \"2024-02-01\"]\n",
    "    amounts: Optional[List[float]]  # [1500.00, 2300.50]\n",
    "    \n",
    "    # Summary (set by summarize node)\n",
    "    summary: Optional[str]\n",
    "    \n",
    "    # Routing decision (set by router)\n",
    "    next_step: Optional[str]  # \"approve\", \"reject\", \"review\"\n",
    "    \n",
    "    # Metadata\n",
    "    processed_at: Optional[str]\n",
    "    errors: Optional[List[str]]\n",
    "\n",
    "print(\"‚úÖ Well-designed state schema!\")\n",
    "print(\"\\nKey features:\")\n",
    "print(\"1. Clear input vs output fields\")\n",
    "print(\"2. Optional fields for values set later\")\n",
    "print(\"3. Specific types (List[dict], float, etc.)\")\n",
    "print(\"4. Docstrings for clarity\")\n",
    "print(\"5. Error tracking built-in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Nodes ‚Äî The Workflow Steps\n",
    "\n",
    "**Nodes** are functions that:\n",
    "- Take state as input\n",
    "- Perform work (call LLM, API, database, etc.)\n",
    "- Return updated state\n",
    "\n",
    "**Node Types:**\n",
    "1. **Processing nodes**: Transform data (classify, extract, summarize)\n",
    "2. **Decision nodes**: Analyze state and set routing flags\n",
    "3. **Integration nodes**: Call external APIs/databases\n",
    "4. **Validation nodes**: Check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from datetime import datetime\n",
    "\n",
    "class DocState(TypedDict):\n",
    "    text: str\n",
    "    doc_type: str\n",
    "    entities: list\n",
    "    summary: str\n",
    "    error: str\n",
    "    timestamp: str\n",
    "\n",
    "# Example 1: Processing Node\n",
    "def classify_document(state: DocState) -> DocState:\n",
    "    \"\"\"Classify document type using keyword matching.\"\"\"\n",
    "    text_lower = state[\"text\"].lower()\n",
    "    \n",
    "    if \"invoice\" in text_lower or \"payment\" in text_lower:\n",
    "        state[\"doc_type\"] = \"invoice\"\n",
    "    elif \"agreement\" in text_lower or \"contract\" in text_lower:\n",
    "        state[\"doc_type\"] = \"contract\"\n",
    "    else:\n",
    "        state[\"doc_type\"] = \"report\"\n",
    "    \n",
    "    state[\"timestamp\"] = datetime.now().isoformat()\n",
    "    return state\n",
    "\n",
    "# Example 2: Extraction Node\n",
    "def extract_entities(state: DocState) -> DocState:\n",
    "    \"\"\"Extract key entities from document.\"\"\"\n",
    "    # In production: use NER model or LLM\n",
    "    entities = []\n",
    "    \n",
    "    # Simple extraction example\n",
    "    if \"$\" in state[\"text\"]:\n",
    "        entities.append({\"type\": \"amount\", \"value\": \"$1,500\"})\n",
    "    \n",
    "    state[\"entities\"] = entities\n",
    "    return state\n",
    "\n",
    "# Example 3: Summarization Node (with LLM)\n",
    "def summarize_document(state: DocState) -> DocState:\n",
    "    \"\"\"Generate concise summary.\"\"\"\n",
    "    # In production: use actual LLM\n",
    "    doc_type = state.get(\"doc_type\", \"document\")\n",
    "    state[\"summary\"] = f\"This is a {doc_type} containing {len(state['text'])} characters.\"\n",
    "    return state\n",
    "\n",
    "# Example 4: Error Handling Node\n",
    "def validate_document(state: DocState) -> DocState:\n",
    "    \"\"\"Validate document before processing.\"\"\"\n",
    "    if not state.get(\"text\"):\n",
    "        state[\"error\"] = \"Empty document\"\n",
    "    elif len(state[\"text\"]) < 10:\n",
    "        state[\"error\"] = \"Document too short\"\n",
    "    else:\n",
    "        state[\"error\"] = \"\"  # No error\n",
    "    return state\n",
    "\n",
    "print(\"‚úÖ Node functions created!\")\n",
    "print(\"\\nüí° Node Best Practices:\")\n",
    "print(\"1. Single responsibility (do ONE thing well)\")\n",
    "print(\"2. Always return state (even if unchanged)\")\n",
    "print(\"3. Handle errors gracefully (don't crash)\")\n",
    "print(\"4. Add logging for debugging\")\n",
    "print(\"5. Keep nodes pure (no hidden side effects)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Edges ‚Äî Connecting the Workflow\n",
    "\n",
    "**Edge Types:**\n",
    "\n",
    "1. **Normal Edges**: Always go from A ‚Üí B\n",
    "   ```python\n",
    "   workflow.add_edge(\"node_a\", \"node_b\")\n",
    "   ```\n",
    "\n",
    "2. **Conditional Edges**: Route based on state\n",
    "   ```python\n",
    "   workflow.add_conditional_edges(\n",
    "       \"router_node\",\n",
    "       routing_function,\n",
    "       {\"option1\": \"node_a\", \"option2\": \"node_b\"}\n",
    "   )\n",
    "   ```\n",
    "\n",
    "3. **Entry Point**: Where execution starts\n",
    "   ```python\n",
    "   workflow.set_entry_point(\"first_node\")\n",
    "   ```\n",
    "\n",
    "4. **End**: Terminal node (no outgoing edges)\n",
    "   ```python\n",
    "   workflow.add_edge(\"final_node\", END)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "class SimpleState(TypedDict):\n",
    "    value: int\n",
    "    path_taken: str\n",
    "\n",
    "# Example: Conditional routing based on value\n",
    "def check_value(state: SimpleState) -> Literal[\"low\", \"high\"]:\n",
    "    \"\"\"Router: decide path based on value.\"\"\"\n",
    "    return \"low\" if state[\"value\"] < 50 else \"high\"\n",
    "\n",
    "def process_low(state: SimpleState) -> SimpleState:\n",
    "    state[\"path_taken\"] = \"LOW path\"\n",
    "    return state\n",
    "\n",
    "def process_high(state: SimpleState) -> SimpleState:\n",
    "    state[\"path_taken\"] = \"HIGH path\"\n",
    "    return state\n",
    "\n",
    "# Build graph with conditional routing\n",
    "graph = StateGraph(SimpleState)\n",
    "graph.add_node(\"process_low\", process_low)\n",
    "graph.add_node(\"process_high\", process_high)\n",
    "\n",
    "graph.set_conditional_entry_point(\n",
    "    check_value,\n",
    "    {\"low\": \"process_low\", \"high\": \"process_high\"}\n",
    ")\n",
    "\n",
    "graph.add_edge(\"process_low\", END)\n",
    "graph.add_edge(\"process_high\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# Test routing\n",
    "print(\"üß™ Test conditional routing:\")\n",
    "print()\n",
    "result1 = app.invoke({\"value\": 25})\n",
    "print(f\"Value=25 ‚Üí {result1['path_taken']}\")\n",
    "\n",
    "result2 = app.invoke({\"value\": 75})\n",
    "print(f\"Value=75 ‚Üí {result2['path_taken']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Routing works! Different inputs take different paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Part 3: Building a Real Document Processing Pipeline\n",
    "\n",
    "<div class=\"scenario-box\">\n",
    "<strong>üìå Scenario:</strong> Build an intelligent document processor for a financial services company:\n",
    "<ol>\n",
    "<li><strong>Classify</strong> document type (invoice, contract, report, form)</li>\n",
    "<li><strong>Extract</strong> key information (dates, amounts, parties)</li>\n",
    "<li><strong>Validate</strong> extracted data</li>\n",
    "<li><strong>Summarize</strong> document content</li>\n",
    "<li><strong>Route</strong> for appropriate action:\n",
    "  <ul>\n",
    "    <li>Invoice ‚Üí Accounting system</li>\n",
    "    <li>Contract ‚Üí Legal review</li>\n",
    "    <li>Report ‚Üí Management dashboard</li>\n",
    "    <li>Unknown ‚Üí Human review</li>\n",
    "  </ul>\n",
    "</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "### Step 1: Define Comprehensive State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional, List, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "class DocumentState(TypedDict):\n",
    "    \"\"\"State for document processing workflow.\"\"\"\n",
    "    \n",
    "    # Input\n",
    "    document_id: str\n",
    "    document_text: str\n",
    "    source: str  # \"email\", \"upload\", \"scan\"\n",
    "    \n",
    "    # Classification\n",
    "    document_type: Optional[str]  # \"invoice\", \"contract\", \"report\", \"form\", \"unknown\"\n",
    "    classification_confidence: Optional[float]\n",
    "    language: Optional[str]\n",
    "    \n",
    "    # Extraction\n",
    "    entities: Optional[List[Dict[str, str]]]  # [{\"type\": \"amount\", \"value\": \"$1500\"}]\n",
    "    dates: Optional[List[str]]\n",
    "    amounts: Optional[List[float]]\n",
    "    parties: Optional[List[str]]  # People/companies mentioned\n",
    "    \n",
    "    # Validation\n",
    "    is_valid: Optional[bool]\n",
    "    validation_errors: Optional[List[str]]\n",
    "    \n",
    "    # Summary\n",
    "    summary: Optional[str]\n",
    "    key_points: Optional[List[str]]\n",
    "    \n",
    "    # Routing\n",
    "    routing_decision: Optional[str]  # \"accounting\", \"legal\", \"management\", \"review\"\n",
    "    priority: Optional[str]  # \"low\", \"medium\", \"high\", \"urgent\"\n",
    "    \n",
    "    # Metadata\n",
    "    processing_started: Optional[str]\n",
    "    processing_completed: Optional[str]\n",
    "    errors: Optional[List[str]]\n",
    "\n",
    "print(\"‚úÖ DocumentState schema defined\")\n",
    "print(f\"\\nTotal fields: {len(DocumentState.__annotations__)}\")\n",
    "print(\"Input fields: 3\")\n",
    "print(\"Processing fields: 14\")\n",
    "print(\"Metadata fields: 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Processing Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Node 1: Classify Document\n",
    "def classify_document(state: DocumentState) -> DocumentState:\n",
    "    \"\"\"Classify document type using keyword analysis.\"\"\"\n",
    "    text_lower = state[\"document_text\"].lower()\n",
    "    \n",
    "    # Classification logic (in production: use LLM)\n",
    "    if any(word in text_lower for word in [\"invoice\", \"payment\", \"bill\", \"amount due\"]):\n",
    "        state[\"document_type\"] = \"invoice\"\n",
    "        state[\"classification_confidence\"] = 0.92\n",
    "    elif any(word in text_lower for word in [\"agreement\", \"contract\", \"hereby agree\"]):\n",
    "        state[\"document_type\"] = \"contract\"\n",
    "        state[\"classification_confidence\"] = 0.88\n",
    "    elif any(word in text_lower for word in [\"report\", \"analysis\", \"findings\"]):\n",
    "        state[\"document_type\"] = \"report\"\n",
    "        state[\"classification_confidence\"] = 0.85\n",
    "    else:\n",
    "        state[\"document_type\"] = \"unknown\"\n",
    "        state[\"classification_confidence\"] = 0.40\n",
    "    \n",
    "    # Detect language (simplified)\n",
    "    state[\"language\"] = \"en\"  # Default to English\n",
    "    \n",
    "    state[\"processing_started\"] = datetime.now().isoformat()\n",
    "    return state\n",
    "\n",
    "# Node 2: Extract Information\n",
    "def extract_information(state: DocumentState) -> DocumentState:\n",
    "    \"\"\"Extract key entities, dates, amounts from document.\"\"\"\n",
    "    text = state[\"document_text\"]\n",
    "    \n",
    "    # Extract dates (simple regex)\n",
    "    date_pattern = r'\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}'\n",
    "    dates = re.findall(date_pattern, text)\n",
    "    state[\"dates\"] = dates if dates else []\n",
    "    \n",
    "    # Extract amounts (simple regex)\n",
    "    amount_pattern = r'\\$\\s*([0-9,]+\\.?[0-9]*)'\n",
    "    amounts_str = re.findall(amount_pattern, text)\n",
    "    state[\"amounts\"] = [float(amt.replace(',', '')) for amt in amounts_str]\n",
    "    \n",
    "    # Extract entities\n",
    "    entities = []\n",
    "    if state[\"amounts\"]:\n",
    "        entities.append({\"type\": \"monetary_amount\", \"value\": f\"${state['amounts'][0]}\"})\n",
    "    if state[\"dates\"]:\n",
    "        entities.append({\"type\": \"date\", \"value\": state['dates'][0]})\n",
    "    state[\"entities\"] = entities\n",
    "    \n",
    "    # Extract parties (simplified - just capitalized words)\n",
    "    parties = re.findall(r'\\b[A-Z][a-z]+ [A-Z][a-z]+\\b', text)\n",
    "    state[\"parties\"] = list(set(parties))[:5]  # Top 5 unique\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Node 3: Validate Data\n",
    "def validate_extraction(state: DocumentState) -> DocumentState:\n",
    "    \"\"\"Validate extracted information.\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    # Validation rules\n",
    "    if state[\"document_type\"] == \"invoice\":\n",
    "        if not state.get(\"amounts\"):\n",
    "            errors.append(\"Invoice missing amount\")\n",
    "        if not state.get(\"dates\"):\n",
    "            errors.append(\"Invoice missing date\")\n",
    "    \n",
    "    if state[\"document_type\"] == \"contract\":\n",
    "        if not state.get(\"parties\") or len(state.get(\"parties\", [])) < 2:\n",
    "            errors.append(\"Contract missing parties\")\n",
    "    \n",
    "    if state[\"classification_confidence\"] < 0.7:\n",
    "        errors.append(\"Low classification confidence\")\n",
    "    \n",
    "    state[\"is_valid\"] = len(errors) == 0\n",
    "    state[\"validation_errors\"] = errors\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Node 4: Summarize Document\n",
    "def summarize_document(state: DocumentState) -> DocumentState:\n",
    "    \"\"\"Generate summary and key points.\"\"\"\n",
    "    doc_type = state[\"document_type\"]\n",
    "    \n",
    "    # Generate summary based on type\n",
    "    if doc_type == \"invoice\":\n",
    "        amount = state[\"amounts\"][0] if state.get(\"amounts\") else \"unknown\"\n",
    "        date = state[\"dates\"][0] if state.get(\"dates\") else \"unknown\"\n",
    "        state[\"summary\"] = f\"Invoice for ${amount} dated {date}\"\n",
    "        state[\"key_points\"] = [\n",
    "            f\"Amount due: ${amount}\",\n",
    "            f\"Date: {date}\",\n",
    "            f\"Entities extracted: {len(state.get('entities', []))}\"\n",
    "        ]\n",
    "    elif doc_type == \"contract\":\n",
    "        parties = state.get(\"parties\", [])\n",
    "        state[\"summary\"] = f\"Contract agreement between {len(parties)} parties\"\n",
    "        state[\"key_points\"] = [\n",
    "            f\"Parties: {', '.join(parties[:3])}\",\n",
    "            f\"Dates mentioned: {len(state.get('dates', []))}\"\n",
    "        ]\n",
    "    else:\n",
    "        state[\"summary\"] = f\"{doc_type.title()} document with {len(state['document_text'])} characters\"\n",
    "        state[\"key_points\"] = [f\"Type: {doc_type}\", f\"Language: {state.get('language', 'unknown')}\"]\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Node 5: Route Document\n",
    "def route_document(state: DocumentState) -> DocumentState:\n",
    "    \"\"\"Determine routing and priority.\"\"\"\n",
    "    doc_type = state[\"document_type\"]\n",
    "    is_valid = state.get(\"is_valid\", False)\n",
    "    \n",
    "    # Routing logic\n",
    "    if not is_valid:\n",
    "        state[\"routing_decision\"] = \"review\"\n",
    "        state[\"priority\"] = \"high\"\n",
    "    elif doc_type == \"invoice\":\n",
    "        state[\"routing_decision\"] = \"accounting\"\n",
    "        # Check if urgent (amount > $10,000)\n",
    "        amounts = state.get(\"amounts\", [])\n",
    "        state[\"priority\"] = \"urgent\" if (amounts and amounts[0] > 10000) else \"medium\"\n",
    "    elif doc_type == \"contract\":\n",
    "        state[\"routing_decision\"] = \"legal\"\n",
    "        state[\"priority\"] = \"high\"\n",
    "    elif doc_type == \"report\":\n",
    "        state[\"routing_decision\"] = \"management\"\n",
    "        state[\"priority\"] = \"low\"\n",
    "    else:\n",
    "        state[\"routing_decision\"] = \"review\"\n",
    "        state[\"priority\"] = \"medium\"\n",
    "    \n",
    "    state[\"processing_completed\"] = datetime.now().isoformat()\n",
    "    return state\n",
    "\n",
    "print(\"‚úÖ All node functions implemented!\")\n",
    "print(\"\\nNodes created:\")\n",
    "print(\"  1. classify_document\")\n",
    "print(\"  2. extract_information\")\n",
    "print(\"  3. validate_extraction\")\n",
    "print(\"  4. summarize_document\")\n",
    "print(\"  5. route_document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Build the Complete Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(DocumentState)\n",
    "\n",
    "# Add all nodes\n",
    "workflow.add_node(\"classify\", classify_document)\n",
    "workflow.add_node(\"extract\", extract_information)\n",
    "workflow.add_node(\"validate\", validate_extraction)\n",
    "workflow.add_node(\"summarize\", summarize_document)\n",
    "workflow.add_node(\"route\", route_document)\n",
    "\n",
    "# Define the workflow\n",
    "workflow.set_entry_point(\"classify\")\n",
    "workflow.add_edge(\"classify\", \"extract\")\n",
    "workflow.add_edge(\"extract\", \"validate\")\n",
    "workflow.add_edge(\"validate\", \"summarize\")\n",
    "workflow.add_edge(\"summarize\", \"route\")\n",
    "workflow.add_edge(\"route\", END)\n",
    "\n",
    "# Compile the graph\n",
    "doc_processor = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Document processing graph compiled!\")\n",
    "print(\"\\nüìä WORKFLOW:\")\n",
    "print(\"\"\"\n",
    "    START\n",
    "      |\n",
    "      v\n",
    "  [classify] ‚Üê Determine document type\n",
    "      |\n",
    "      v\n",
    "  [extract] ‚Üê Extract dates, amounts, entities\n",
    "      |\n",
    "      v\n",
    "  [validate] ‚Üê Check data quality\n",
    "      |\n",
    "      v\n",
    "  [summarize] ‚Üê Generate summary\n",
    "      |\n",
    "      v\n",
    "  [route] ‚Üê Determine destination & priority\n",
    "      |\n",
    "      v\n",
    "    END\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Test with Real-World Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Document 1: Invoice\n",
    "invoice_doc = {\n",
    "    \"document_id\": \"DOC-001\",\n",
    "    \"source\": \"email\",\n",
    "    \"document_text\": \"\"\"\n",
    "    INVOICE #INV-2024-001\n",
    "    \n",
    "    Date: 01/15/2024\n",
    "    Due Date: 02/15/2024\n",
    "    \n",
    "    Bill To: Acme Corporation\n",
    "    From: Tech Solutions Inc\n",
    "    \n",
    "    Services Rendered:\n",
    "    - Software Development: $15,000.00\n",
    "    - Cloud Hosting (Jan): $2,500.00\n",
    "    \n",
    "    Total Amount Due: $17,500.00\n",
    "    \n",
    "    Payment Terms: Net 30\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "print(\"üß™ TEST 1: Processing Invoice\")\n",
    "print(\"=\" * 70)\n",
    "result = doc_processor.invoke(invoice_doc)\n",
    "\n",
    "print(f\"Document ID: {result['document_id']}\")\n",
    "print(f\"Source: {result['source']}\")\n",
    "print()\n",
    "print(f\"üìã Classification:\")\n",
    "print(f\"  Type: {result['document_type']}\")\n",
    "print(f\"  Confidence: {result['classification_confidence']:.0%}\")\n",
    "print(f\"  Language: {result['language']}\")\n",
    "print()\n",
    "print(f\"üìä Extraction:\")\n",
    "print(f\"  Dates found: {len(result['dates'])} ‚Üí {result['dates']}\")\n",
    "print(f\"  Amounts found: {len(result['amounts'])} ‚Üí ${result['amounts']}\")\n",
    "print(f\"  Entities: {len(result['entities'])}\")\n",
    "for entity in result['entities']:\n",
    "    print(f\"    - {entity['type']}: {entity['value']}\")\n",
    "print()\n",
    "print(f\"‚úì Validation:\")\n",
    "print(f\"  Valid: {result['is_valid']}\")\n",
    "if result['validation_errors']:\n",
    "    print(f\"  Errors: {result['validation_errors']}\")\n",
    "print()\n",
    "print(f\"üìù Summary:\")\n",
    "print(f\"  {result['summary']}\")\n",
    "print(f\"  Key Points:\")\n",
    "for point in result['key_points']:\n",
    "    print(f\"    ‚Ä¢ {point}\")\n",
    "print()\n",
    "print(f\"üéØ Routing:\")\n",
    "print(f\"  Destination: {result['routing_decision'].upper()}\")\n",
    "print(f\"  Priority: {result['priority'].upper()}\")\n",
    "print()\n",
    "print(f\"‚è±Ô∏è Processing Time: {result['processing_started'][:19]} ‚Üí {result['processing_completed'][:19]}\")\n",
    "print(\"=\" * 70)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Document 2: Contract\n",
    "contract_doc = {\n",
    "    \"document_id\": \"DOC-002\",\n",
    "    \"source\": \"upload\",\n",
    "    \"document_text\": \"\"\"\n",
    "    SERVICE AGREEMENT\n",
    "    \n",
    "    This agreement is entered into on 2024-01-10 between:\n",
    "    \n",
    "    Party A: John Smith, representing Smith Enterprises LLC\n",
    "    Party B: Jane Doe, representing Doe Consulting Inc\n",
    "    \n",
    "    The parties hereby agree to the following terms:\n",
    "    \n",
    "    1. Services: Consulting services for digital transformation\n",
    "    2. Duration: 6 months starting 2024-02-01\n",
    "    3. Compensation: $5,000.00 per month\n",
    "    4. Termination: Either party may terminate with 30 days notice\n",
    "    \n",
    "    Signed on 2024-01-10\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "print(\"üß™ TEST 2: Processing Contract\")\n",
    "print(\"=\" * 70)\n",
    "result = doc_processor.invoke(contract_doc)\n",
    "\n",
    "print(f\"üìã Classification: {result['document_type']} ({result['classification_confidence']:.0%})\")\n",
    "print(f\"üìä Parties Identified: {', '.join(result['parties'])}\")\n",
    "print(f\"‚úì Valid: {result['is_valid']}\")\n",
    "print(f\"üìù Summary: {result['summary']}\")\n",
    "print(f\"üéØ Route to: {result['routing_decision'].upper()} (Priority: {result['priority'].upper()})\")\n",
    "print(\"=\" * 70)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Document 3: Unknown/Ambiguous\n",
    "unknown_doc = {\n",
    "    \"document_id\": \"DOC-003\",\n",
    "    \"source\": \"scan\",\n",
    "    \"document_text\": \"Hello, this is a short note. Thanks!\"\n",
    "}\n",
    "\n",
    "print(\"üß™ TEST 3: Processing Unknown Document\")\n",
    "print(\"=\" * 70)\n",
    "result = doc_processor.invoke(unknown_doc)\n",
    "\n",
    "print(f\"üìã Classification: {result['document_type']} ({result['classification_confidence']:.0%})\")\n",
    "print(f\"‚úì Valid: {result['is_valid']}\")\n",
    "if result['validation_errors']:\n",
    "    print(f\"‚ö†Ô∏è Validation Errors:\")\n",
    "    for error in result['validation_errors']:\n",
    "        print(f\"  ‚Ä¢ {error}\")\n",
    "print(f\"üéØ Route to: {result['routing_decision'].upper()} (Priority: {result['priority'].upper()})\")\n",
    "print(\"\\n‚úÖ Notice: Low confidence ‚Üí routed to human review!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Hands-On Exercises\n",
    "\n",
    "<div class=\"exercise-box\">\n",
    "<strong>üéØ Exercise 1: Add Error Handling</strong>\n",
    "<br><br>\n",
    "Enhance the document processor with robust error handling:\n",
    "<ol>\n",
    "<li>Add a <code>try/except</code> wrapper to each node</li>\n",
    "<li>If a node fails, log the error to <code>state[\"errors\"]</code></li>\n",
    "<li>Add an error recovery node that handles failures</li>\n",
    "<li>Test with malformed input (empty text, None values)</li>\n",
    "</ol>\n",
    "<br>\n",
    "<strong>Hint:</strong> Create a wrapper function:\n",
    "<pre><code>def safe_node(node_fn):\n",
    "    def wrapper(state):\n",
    "        try:\n",
    "            return node_fn(state)\n",
    "        except Exception as e:\n",
    "            state[\"errors\"] = state.get(\"errors\", []) + [str(e)]\n",
    "            return state\n",
    "    return wrapper\n",
    "</code></pre>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here!\n",
    "\n",
    "# TODO: Create safe_node wrapper\n",
    "# TODO: Wrap all nodes with error handling\n",
    "# TODO: Add error recovery node\n",
    "# TODO: Test with bad inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise-box\">\n",
    "<strong>üéØ Exercise 2: Add Conditional Routing</strong>\n",
    "<br><br>\n",
    "Modify the graph to skip summarization for invalid documents:\n",
    "<ol>\n",
    "<li>After <code>validate</code> node, add conditional routing</li>\n",
    "<li>If <code>is_valid == True</code> ‚Üí go to <code>summarize</code></li>\n",
    "<li>If <code>is_valid == False</code> ‚Üí skip directly to <code>route</code></li>\n",
    "<li>Test with both valid and invalid documents</li>\n",
    "</ol>\n",
    "<br>\n",
    "<strong>Hint:</strong> Use <code>add_conditional_edges</code>:\n",
    "<pre><code>def route_after_validation(state):\n",
    "    return \"summarize\" if state[\"is_valid\"] else \"route\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"validate\",\n",
    "    route_after_validation,\n",
    "    {\"summarize\": \"summarize\", \"route\": \"route\"}\n",
    ")\n",
    "</code></pre>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here!\n",
    "\n",
    "# TODO: Define routing function\n",
    "# TODO: Rebuild graph with conditional edges\n",
    "# TODO: Test with valid and invalid docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise-box\">\n",
    "<strong>üéØ Exercise 3: Add Parallel Processing</strong>\n",
    "<br><br>\n",
    "Some operations can run in parallel. Modify the graph to:\n",
    "<ol>\n",
    "<li>After <code>classify</code>, run <code>extract</code> AND <code>detect_language</code> in parallel</li>\n",
    "<li>Create a new <code>detect_language</code> node (use simple heuristics)</li>\n",
    "<li>Both should finish before moving to <code>validate</code></li>\n",
    "</ol>\n",
    "<br>\n",
    "<strong>Challenge:</strong> Research how to add parallel branches in LangGraph!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here!\n",
    "\n",
    "# TODO: Create detect_language node\n",
    "# TODO: Add parallel branches\n",
    "# TODO: Test and measure performance improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Week 1 Project: Content Moderation Pipeline\n",
    "\n",
    "**Build a complete content moderation system for a social media platform.**\n",
    "\n",
    "### Requirements:\n",
    "\n",
    "**Input:** User-generated content (posts, comments)\n",
    "\n",
    "**Workflow:**\n",
    "1. **Classify** content type (text, spam, promotional, news)\n",
    "2. **Detect** toxicity level (clean, mild, toxic, severe)\n",
    "3. **Check** for policy violations (hate speech, misinformation, etc.)\n",
    "4. **Route** based on results:\n",
    "   - Clean ‚Üí Auto-approve\n",
    "   - Mild ‚Üí Add warning label\n",
    "   - Toxic ‚Üí Queue for review\n",
    "   - Severe ‚Üí Auto-reject + alert moderators\n",
    "5. **Log** all decisions for audit trail\n",
    "\n",
    "### State Schema:\n",
    "```python\n",
    "class ModerationState(TypedDict):\n",
    "    content_id: str\n",
    "    content_text: str\n",
    "    author_id: str\n",
    "    \n",
    "    content_type: Optional[str]\n",
    "    toxicity_score: Optional[float]  # 0.0-1.0\n",
    "    policy_violations: Optional[List[str]]\n",
    "    \n",
    "    decision: Optional[str]  # \"approve\", \"warn\", \"review\", \"reject\"\n",
    "    reason: Optional[str]\n",
    "    \n",
    "    processed_at: Optional[str]\n",
    "```\n",
    "\n",
    "### Deliverables:\n",
    "1. Complete state schema\n",
    "2. 5+ node functions (classify, detect, check, route, log)\n",
    "3. Graph with conditional routing\n",
    "4. Test with 5 different content examples:\n",
    "   - Clean post\n",
    "   - Spam\n",
    "   - Mild toxicity\n",
    "   - Severe violation\n",
    "   - Edge case (sarcasm, ambiguous)\n",
    "5. ASCII diagram of your graph\n",
    "\n",
    "### Bonus Challenges:\n",
    "- Add retry logic for failed API calls\n",
    "- Implement appeal mechanism (human override)\n",
    "- Add metrics tracking (approval rate, false positives)\n",
    "- Support multiple languages\n",
    "\n",
    "### Starter Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content Moderation Project Starter\n",
    "\n",
    "from typing import TypedDict, Optional, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# TODO: Define ModerationState\n",
    "class ModerationState(TypedDict):\n",
    "    pass  # Your state schema here\n",
    "\n",
    "# TODO: Implement nodes\n",
    "def classify_content(state: ModerationState) -> ModerationState:\n",
    "    pass  # Your implementation\n",
    "\n",
    "def detect_toxicity(state: ModerationState) -> ModerationState:\n",
    "    pass  # Your implementation\n",
    "\n",
    "# TODO: Build graph\n",
    "# TODO: Test with examples\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    {\"content_id\": \"1\", \"author_id\": \"user123\", \"content_text\": \"Great product! Highly recommend.\"},\n",
    "    {\"content_id\": \"2\", \"author_id\": \"user456\", \"content_text\": \"BUY NOW!!! 50% OFF CLICK HERE!!!\"},\n",
    "    {\"content_id\": \"3\", \"author_id\": \"user789\", \"content_text\": \"This is stupid and annoying.\"},\n",
    "    {\"content_id\": \"4\", \"author_id\": \"user000\", \"content_text\": \"I hate you all! Worst people ever!\"},\n",
    "    {\"content_id\": \"5\", \"author_id\": \"user111\", \"content_text\": \"Yeah right, like that's gonna work... üôÑ\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "**What you learned this week:**\n",
    "\n",
    "‚úÖ **State Graphs > Linear Chains:**\n",
    "- Shared state accessible by all nodes\n",
    "- Conditional routing based on runtime values\n",
    "- Support for cycles and parallel execution\n",
    "- Better debugging and visualization\n",
    "\n",
    "‚úÖ **Core Components:**\n",
    "- **State**: TypedDict with all workflow data\n",
    "- **Nodes**: Functions that transform state\n",
    "- **Edges**: Normal (fixed) or conditional (dynamic)\n",
    "- **Entry/Exit**: START and END points\n",
    "\n",
    "‚úÖ **Real-World Application:**\n",
    "- Built document processing pipeline\n",
    "- Implemented classification, extraction, validation\n",
    "- Added routing logic for different document types\n",
    "- Handled errors and edge cases\n",
    "\n",
    "‚úÖ **Best Practices:**\n",
    "- Design state schema first (types matter!)\n",
    "- Keep nodes small and focused (single responsibility)\n",
    "- Use conditional routing for branching logic\n",
    "- Always handle errors gracefully\n",
    "- Test with diverse inputs (happy path + edge cases)\n",
    "\n",
    "## üîú Next Week: Complex Workflows\n",
    "\n",
    "In Week 2, we'll build advanced workflows with:\n",
    "- **Subgraphs**: Nested workflows for modularity\n",
    "- **Cycles**: Retry logic and iterative refinement\n",
    "- **Parallel Execution**: Speed up independent tasks\n",
    "- **Dynamic Routing**: Complex multi-branch decisions\n",
    "- **Real Project**: Customer onboarding system (50+ steps)\n",
    "\n",
    "**Preview question:** How would you implement a \"retry failed step up to 3 times\" logic in a graph?\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [State Management Guide](https://langchain-ai.github.io/langgraph/concepts/low_level/#state)\n",
    "- [Conditional Edges Examples](https://langchain-ai.github.io/langgraph/how-tos/branching/)\n",
    "- [Graph Visualization Tools](https://langchain-ai.github.io/langgraph/how-tos/visualization/)\n",
    "\n",
    "## üêõ Debugging Tips\n",
    "\n",
    "**Common Issues:**\n",
    "\n",
    "1. **State not updating?**\n",
    "   - Make sure nodes RETURN the updated state\n",
    "   - Check for typos in state keys\n",
    "\n",
    "2. **Conditional routing not working?**\n",
    "   - Verify router function returns exact strings from edge map\n",
    "   - Print state values before routing\n",
    "\n",
    "3. **Graph hangs/infinite loop?**\n",
    "   - Check that all paths eventually reach END\n",
    "   - Look for cycles without exit conditions\n",
    "\n",
    "4. **Type errors?**\n",
    "   - Initialize Optional fields: `state[\"field\"] = None`\n",
    "   - Check TypedDict annotations match actual usage\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations on completing Week 1!** You now know how to build sophisticated, production-ready workflows with LangGraph. See you next week!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
