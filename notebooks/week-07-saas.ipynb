{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 7 \u2014 Applied SaaS Notebook\n\nThis notebook is part of the 'Applied ML Foundations for SaaS Analytics' course. Conversational, mentor-style guidance is provided throughout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "style"
        ]
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\nHTML('''\n<style>\ndetails {\n  margin: 10px 0;\n  padding: 8px 12px;\n  border: 1px solid #d9e2ec;\n  border-radius: 8px;\n  background: #f9fbfd;\n}\ndetails summary {\n  font-weight: 600;\n  color: #0056b3;\n  cursor: pointer;\n}\ndetails[open] {\n  background: #f1f7ff;\n  border-color: #c3d4f0;\n}\ndetails pre {\n  background: #f8f9fa;\n  padding: 8px;\n  border-radius: 6px;\n}\n</style>\n''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario \u2014 Predict which trial users convert to paid\n\nWe will construct features from usage and events, train a classifier, and discuss evaluation metrics meaningful to SaaS (precision at top-N, lift).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hands-on\n\nTry different feature sets and evaluate ROC AUC and precision@k.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n<summary>\ud83d\udca1 Hint</summary>\n\nTry breaking the problem into smaller steps. For example, if you need to aggregate per-user metrics, first compute a grouped table, then convert to NumPy arrays for vectorized ops. Think about edge cases: missing users, zero counts, or extreme values.\n\n</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n<summary>\u2705 Solution (example)</summary>\n\n```python\n# Example solution snippet \u2014 adapt to your dataset & question.\nimport pandas as pd\nimport numpy as np\n\n# Load data (adjust path as needed)\ndf = pd.read_csv('../data/feature_usage.csv', parse_dates=['date'], low_memory=False)\n\n# Example: compute total usage per user and return top users\nuser_usage = df.groupby('user_id')['usage_count'].sum().reset_index(name='total_usage')\ntop_users = user_usage.sort_values('total_usage', ascending=False).head(10)\ntop_users\n```\n\n**Why this works:** We use `groupby` to aggregate events by `user_id`, then sort to find the heaviest users. Converting to NumPy arrays can speed up numeric-only operations.\n\n</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\nimport pandas as pd, numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n# load small samples to build prototype features\nsubs = pd.read_csv('../data/subscriptions.csv')\nfu = pd.read_csv('../data/feature_usage.csv')\n# simple feature: total usage_count per user (sample)\nuser_usage = fu.groupby('user_id')['usage_count'].sum().reset_index()\ndf = subs.merge(user_usage, on='user_id', how='left').fillna(0)\ndf['is_paid'] = (df['mrr']>0).astype(int)\nX = df[['usage_count','tenure_days']].values[:2000]\ny = df['is_paid'].values[:2000]\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\nclf = RandomForestClassifier(n_estimators=50, random_state=42)\nclf.fit(X_train, y_train)\nprint('test score', clf.score(X_test,y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection\n\nWhy might accuracy be misleading when few users convert?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}