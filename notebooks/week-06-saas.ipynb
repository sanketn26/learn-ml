{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 6 ‚Äî Supervised Learning: Classification\n",
        "\n",
        "**Course:** Applied ML Foundations for SaaS Analytics  \n",
        "**Week Focus:** Build classification models to predict customer churn, upgrade likelihood, and segment behavior.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "\n",
        "By the end of this week, you will:\n",
        "- Understand classification algorithms: Logistic Regression, Decision Trees, Random Forests\n",
        "- Build and evaluate classification models\n",
        "- Handle class imbalance in SaaS data\n",
        "- Interpret feature importance\n",
        "- Optimize for business metrics (precision vs recall trade-offs)\n",
        "- Deploy models responsibly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "style"
        ]
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "HTML('''\n",
        "<style>\n",
        "details {\n",
        "  margin: 10px 0;\n",
        "  padding: 8px 12px;\n",
        "  border: 1px solid #d9e2ec;\n",
        "  border-radius: 8px;\n",
        "  background: #f9fbfd;\n",
        "}\n",
        "details summary {\n",
        "  font-weight: 600;\n",
        "  color: #0056b3;\n",
        "  cursor: pointer;\n",
        "}\n",
        "details[open] {\n",
        "  background: #f1f7ff;\n",
        "  border-color: #c3d4f0;\n",
        "}\n",
        "details pre {\n",
        "  background: #f8f9fa;\n",
        "  padding: 8px;\n",
        "  border-radius: 6px;\n",
        "}\n",
        "</style>\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè¢ Scenario ‚Äî Churn Prediction Model\n",
        "\n",
        "Sales wants to identify at-risk customers so they can intervene. Build a model that:\n",
        "- Predicts which customers will churn in the next 30 days\n",
        "- Ranks customers by churn risk\n",
        "- Explains which features drive churn decisions\n",
        "\n",
        "Goal: Actionable predictions for the sales team."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úçÔ∏è Hands-on Exercises\n",
        "\n",
        "1. **Binary Classification**: Train Logistic Regression on churn (Yes/No)\n",
        "2. **Decision Tree**: Build a tree model and visualize feature splits\n",
        "3. **Random Forest**: Train an ensemble and compute feature importance\n",
        "4. **Hyperparameter Tuning**: Use GridSearchCV to find optimal max_depth, n_estimators\n",
        "5. **Evaluation Metrics**: Compute precision, recall, F1, ROC-AUC for each model\n",
        "6. **Business Interpretation**: For top 3 features, explain impact on churn prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>üí° Hint ‚Äî Classification Model Workflow</summary>\n",
        "\n",
        "**Step 1: Prepare Data**\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "```\n",
        "\n",
        "**Step 2: Train Multiple Models**\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "models = {\n",
        "    'logistic': LogisticRegression(),\n",
        "    'forest': RandomForestClassifier(n_estimators=100)\n",
        "}\n",
        "```\n",
        "\n",
        "**Step 3: Evaluate on Test Set**\n",
        "- Accuracy: % correct (bad for imbalanced data!)\n",
        "- Precision: Of predicted positives, % are actually positive\n",
        "- Recall: Of actual positives, % did we catch?\n",
        "- F1-Score: Balance between precision & recall\n",
        "- ROC-AUC: Threshold-independent performance\n",
        "\n",
        "**Step 4: Choose Metric for Your Goal**\n",
        "- Minimize false positives (costly interventions): Precision\n",
        "- Minimize false negatives (can't lose customers): Recall\n",
        "- Balance both: F1 or threshold tuning\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>‚úÖ Solution ‚Äî End-to-End Churn Classification</summary>\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "\n",
        "# Prepare data (from Week 5 feature engineering)\n",
        "subs = pd.read_csv('../data/subscriptions.csv', parse_dates=['signup_date','churn_date'])\n",
        "feature_usage = pd.read_csv('../data/feature_usage.csv')\n",
        "\n",
        "user_features = feature_usage.groupby('user_id').agg({\n",
        "    'usage_count': 'sum',\n",
        "    'feature_name': 'nunique'\n",
        "}).reset_index()\n",
        "user_features.columns = ['user_id', 'total_usage', 'num_features']\n",
        "\n",
        "df = subs.merge(user_features, how='left')\n",
        "df['total_usage'] = df['total_usage'].fillna(0)\n",
        "df['num_features'] = df['num_features'].fillna(0)\n",
        "df['target'] = df['churn_date'].notna().astype(int)\n",
        "\n",
        "# Features and target\n",
        "X = df[['total_usage', 'num_features']]\n",
        "y = df['target']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = rf.predict(X_test)\n",
        "y_pred_proba = rf.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Active', 'Churned']))\n",
        "print(f\"\\nROC-AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "for feature, importance in zip(X.columns, rf.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.3f}\")\n",
        "```\n",
        "\n",
        "**Key insight:** Feature adoption is the strongest churn predictor. Invest in onboarding!\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"WEEK 6: CLASSIFICATION MODEL DEMO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Prepare data\n",
        "subs = pd.read_csv('../data/subscriptions.csv', parse_dates=['signup_date','churn_date'])\n",
        "feature_usage = pd.read_csv('../data/feature_usage.csv')\n",
        "\n",
        "user_features = feature_usage.groupby('user_id').agg({\n",
        "    'usage_count': 'sum',\n",
        "    'feature_name': 'nunique'\n",
        "}).reset_index()\n",
        "user_features.columns = ['user_id', 'total_usage', 'num_features']\n",
        "\n",
        "df = subs.merge(user_features, how='left')\n",
        "df['total_usage'] = df['total_usage'].fillna(0)\n",
        "df['num_features'] = df['num_features'].fillna(0)\n",
        "df['target'] = df['churn_date'].notna().astype(int)\n",
        "\n",
        "print(f\"\\nDataset: {len(df)} customers\")\n",
        "print(f\"Churn rate: {df['target'].mean():.1%}\")\n",
        "\n",
        "# Prepare features\n",
        "X = df[['total_usage', 'num_features']]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\n1. LOGISTIC REGRESSION\")\n",
        "print(\"-\" * 70)\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_auc = roc_auc_score(y_test, lr.predict_proba(X_test)[:,1])\n",
        "print(f\"ROC-AUC: {lr_auc:.4f}\")\n",
        "\n",
        "print(\"\\n2. RANDOM FOREST\")\n",
        "print(\"-\" * 70)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:,1])\n",
        "print(f\"ROC-AUC: {rf_auc:.4f}\")\n",
        "\n",
        "print(\"\\n3. FEATURE IMPORTANCE (Random Forest)\")\n",
        "print(\"-\" * 70)\n",
        "for feature, importance in zip(X.columns, rf.feature_importances_):\n",
        "    print(f\"{feature:.<30} {importance:.2%}\")\n",
        "\n",
        "print(\"\\n4. BUSINESS APPLICATION\")\n",
        "print(\"-\" * 70)\n",
        "# Get top 20% at-risk customers\n",
        "risk_scores = rf.predict_proba(X)[:,1]\n",
        "df['churn_risk'] = risk_scores\n",
        "high_risk = df[df['churn_risk'] >= df['churn_risk'].quantile(0.80)]\n",
        "print(f\"High-risk segment (top 20%): {len(high_risk)} customers\")\n",
        "print(f\"Their actual churn rate: {high_risk['target'].mean():.1%}\")\n",
        "print(f\"Overall churn rate: {df['target'].mean():.1%}\")\n",
        "print(f\"Lift: {high_risk['target'].mean() / df['target'].mean():.1f}x\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Key Concepts ‚Äî Classification Metrics Explained\n",
        "\n",
        "### Confusion Matrix\n",
        "```\n",
        "                 Predicted\n",
        "                Positive  Negative\n",
        "Actual\n",
        "Positive    TP (correct)   FN (miss)\n",
        "Negative    FP (false alarm) TN (correct)\n",
        "```\n",
        "\n",
        "### Metric Definitions\n",
        "- **Accuracy**: (TP + TN) / All ‚Äî overall correctness (can be misleading!)\n",
        "- **Precision**: TP / (TP + FP) ‚Äî of predictions, how many right?\n",
        "- **Recall**: TP / (TP + FN) ‚Äî of actual positives, how many caught?\n",
        "- **F1**: Harmonic mean of precision & recall\n",
        "- **ROC-AUC**: How well does the model rank positives higher than negatives?\n",
        "\n",
        "### Churn Prediction Trade-off Example\n",
        "- **High precision**: Only warn on very confident churners (miss some)\n",
        "- **High recall**: Warn on anyone at slight risk (false alarms)\n",
        "- **Business choice**: Sales can handle false alarms; can't afford to miss true churners ‚Üí prioritize recall\n",
        "\n",
        "## ü§î Reflection & Application\n",
        "\n",
        "**Question 1:** Your model achieves 95% accuracy but only 10% recall on churners. Is it good?\n",
        "- No! It's predicting everyone stays (easy baseline on imbalanced data)\n",
        "- Always check recall separately; use business metric\n",
        "\n",
        "**Question 2:** How do you explain model predictions to sales?\n",
        "- Feature importance: \"Customers with < 3 features adopted churn 5x more\"\n",
        "- SHAP values: Individual prediction reasons\n",
        "- Decision trees: Visualize decision path\n",
        "\n",
        "**Question 3:** When should you retrain the model?\n",
        "- Monthly at minimum (customer behavior changes)\n",
        "- Immediately if model performance drops\n",
        "- When you add new data sources or business rules\n",
        "\n",
        "## üìù Practice Assignment\n",
        "\n",
        "**Problem:** Build a churn intervention strategy:\n",
        "1. Train classification model on historical data\n",
        "2. Generate churn risk scores for all current customers\n",
        "3. Define segments: high/medium/low risk\n",
        "4. For each segment, estimate: % likely to churn, cost to intervene, expected retention\n",
        "5. Recommend: which segment(s) should sales contact?\n",
        "\n",
        "## üîó Next Steps\n",
        "\n",
        "In Week 7, we'll predict continuous values (CLV, revenue) with regression models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
