{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 ‚Äî LangChain Fundamentals & Basic Chains\n",
    "\n",
    "**Course:** LangChain for AI Applications  \n",
    "**Week Focus:** Master LLM fundamentals, prompt engineering, and chain composition to build production-ready AI applications.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this week, you will:\n",
    "- Understand the architecture of modern LLM applications\n",
    "- Build reusable prompt templates with variable injection\n",
    "- Compose simple and sequential chains using LCEL (LangChain Expression Language)\n",
    "- Parse and validate LLM outputs with structured schemas\n",
    "- Handle errors gracefully and implement retry logic\n",
    "- Build a real-world customer support automation system\n",
    "\n",
    "## üìä Real-World Context\n",
    "\n",
    "**The Challenge:** Your SaaS company handles 500+ support tickets daily:\n",
    "- 40% are common questions (password resets, billing inquiries)\n",
    "- 30% are bug reports requiring technical triage\n",
    "- 20% are feature requests needing product team routing\n",
    "- 10% are complex issues requiring human escalation\n",
    "\n",
    "**The Solution:** An intelligent triage system that:\n",
    "1. **Classifies** incoming tickets automatically (bug/feature/question/urgent)\n",
    "2. **Generates** initial responses for common issues\n",
    "3. **Extracts** key information (error messages, account IDs, reproduction steps)\n",
    "4. **Routes** complex cases to appropriate teams\n",
    "5. **Learns** from human feedback to improve over time\n",
    "\n",
    "**Business Impact:**\n",
    "- ‚è±Ô∏è Reduce avg response time from 4 hours ‚Üí 5 minutes\n",
    "- üí∞ Save $120K/year in support costs\n",
    "- üòä Increase customer satisfaction by 35%\n",
    "- üìà Scale support without linear headcount growth\n",
    "\n",
    "Companies like **Intercom, Zendesk, and Notion** use similar LangChain-powered systems in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "style"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "<style>\n",
    ".jp-RenderedHTMLCommon h2 {\n",
    "    color: #2c3e50;\n",
    "    border-bottom: 2px solid #3498db;\n",
    "    padding-bottom: 10px;\n",
    "    margin-top: 30px;\n",
    "}\n",
    ".jp-RenderedHTMLCommon h3 {\n",
    "    color: #34495e;\n",
    "    margin-top: 20px;\n",
    "}\n",
    ".jp-RenderedHTMLCommon code {\n",
    "    background-color: #f8f9fa;\n",
    "    padding: 2px 6px;\n",
    "    border-radius: 3px;\n",
    "    font-family: 'Courier New', monospace;\n",
    "}\n",
    ".jp-RenderedHTMLCommon pre {\n",
    "    background-color: #f8f9fa;\n",
    "    border-left: 4px solid #3498db;\n",
    "    padding: 15px;\n",
    "    border-radius: 5px;\n",
    "}\n",
    ".exercise-box {\n",
    "    background-color: #fff3cd;\n",
    "    border-left: 5px solid #ffc107;\n",
    "    padding: 15px;\n",
    "    margin: 20px 0;\n",
    "    border-radius: 5px;\n",
    "}\n",
    ".scenario-box {\n",
    "    background-color: #d1ecf1;\n",
    "    border-left: 5px solid #17a2b8;\n",
    "    padding: 15px;\n",
    "    margin: 20px 0;\n",
    "    border-radius: 5px;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Part 1: The Problem ‚Äî Why LangChain?\n",
    "\n",
    "### Working Directly with LLM APIs (The Hard Way)\n",
    "\n",
    "Let's see what building an AI application looks like *without* LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Raw OpenAI API call (DON'T DO THIS IN PRODUCTION!)\n",
    "# This is verbose, error-prone, and hard to maintain\n",
    "\n",
    "import os\n",
    "# Uncomment to use (requires OpenAI API key)\n",
    "# import openai\n",
    "\n",
    "# Problems with this approach:\n",
    "raw_code_example = '''\n",
    "# ‚ùå Problem 1: Hardcoded prompts (no reusability)\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a support agent for CloudWave SaaS\"},\n",
    "        {\"role\": \"user\", \"content\": \"My dashboard is loading slowly\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# ‚ùå Problem 2: Deep nested JSON access\n",
    "answer = response['choices'][0]['message']['content']\n",
    "\n",
    "# ‚ùå Problem 3: No output validation\n",
    "# What if the LLM returns invalid JSON? What if it hallucinates?\n",
    "\n",
    "# ‚ùå Problem 4: No error handling\n",
    "# What if API times out? Rate limits? Network errors?\n",
    "\n",
    "# ‚ùå Problem 5: No composability\n",
    "# How do you chain multiple LLM calls? Add memory? Use tools?\n",
    "'''\n",
    "\n",
    "print(\"üö® Challenges with raw LLM APIs:\")\n",
    "print(\"1. Verbose boilerplate code\")\n",
    "print(\"2. No type safety or validation\")\n",
    "print(\"3. Hard to test and debug\")\n",
    "print(\"4. Difficult to chain operations\")\n",
    "print(\"5. No standardization across providers (OpenAI vs Anthropic vs Llama)\")\n",
    "print(\"\\nüí° Solution: LangChain abstracts these complexities!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LangChain Way (Clean, Composable, Production-Ready)\n",
    "\n",
    "LangChain provides:\n",
    "1. **Abstraction**: Unified interface for all LLM providers\n",
    "2. **Composability**: Build complex workflows from simple components\n",
    "3. **Type Safety**: Pydantic models for input/output validation\n",
    "4. **Observability**: Built-in logging, tracing, and debugging\n",
    "5. **Ecosystem**: 100+ integrations (databases, APIs, tools)\n",
    "\n",
    "Let's see the same example, done properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation (uncomment to run):\n",
    "# !pip install langchain langchain-openai python-dotenv\n",
    "\n",
    "# For this demo, we'll use a fake LLM to avoid needing API keys\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ‚úÖ Clean, reusable code with LangChain\n",
    "\n",
    "# 1. Create a prompt template (reusable across all tickets)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful support agent for CloudWave SaaS.\n",
    "    \n",
    "Customer Issue: {user_issue}\n",
    "Customer Tier: {tier}\n",
    "\n",
    "Provide a helpful, professional response.\"\"\"\n",
    ")\n",
    "\n",
    "# 2. Create LLM (swap providers easily: OpenAI, Anthropic, Llama, etc.)\n",
    "# For demo purposes, using a fake LLM with predefined responses\n",
    "llm = FakeListLLM(responses=[\n",
    "    \"Thank you for reporting this issue. Slow dashboard loading can be caused by browser cache. Try clearing your cache (Ctrl+Shift+Del) and reload. If the issue persists, please share your browser version and we'll investigate further.\"\n",
    "])\n",
    "\n",
    "# 3. Create output parser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 4. Compose chain using LCEL (LangChain Expression Language)\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 5. Invoke with inputs\n",
    "result = chain.invoke({\n",
    "    \"user_issue\": \"My dashboard is loading slowly\",\n",
    "    \"tier\": \"Enterprise\"\n",
    "})\n",
    "\n",
    "print(\"ü§ñ AI Response:\")\n",
    "print(result)\n",
    "print(\"\\n‚úÖ Benefits: Readable, testable, swappable components!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Part 2: Core Concepts Deep Dive\n",
    "\n",
    "### 2.1 Prompt Templates ‚Äî Consistency at Scale\n",
    "\n",
    "**Why Templates Matter:**\n",
    "- Reusability: Write once, use 10,000 times\n",
    "- Consistency: Same quality across all interactions\n",
    "- Version Control: Track prompt improvements\n",
    "- A/B Testing: Compare prompt variations\n",
    "\n",
    "**Real-World Example:** GitHub Copilot uses prompt templates to generate code consistently for millions of developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# üîπ Example 1: Simple String Template\n",
    "simple_template = PromptTemplate.from_template(\n",
    "    \"Translate this to {language}: {text}\"\n",
    ")\n",
    "\n",
    "print(\"üìù Simple Template:\")\n",
    "print(simple_template.format(language=\"Spanish\", text=\"Hello, world!\"))\n",
    "print()\n",
    "\n",
    "# üîπ Example 2: Chat Template with System Message\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert {role}. Be {tone}.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    role=\"Python developer\",\n",
    "    tone=\"concise and practical\",\n",
    "    user_input=\"How do I read a CSV file?\"\n",
    ")\n",
    "\n",
    "print(\"üí¨ Chat Template:\")\n",
    "for msg in messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")\n",
    "print()\n",
    "\n",
    "# üîπ Example 3: Few-Shot Learning Template\n",
    "few_shot_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Classify customer sentiment as positive, neutral, or negative.\"),\n",
    "    (\"human\", \"This product is amazing!\"),\n",
    "    (\"assistant\", \"positive\"),\n",
    "    (\"human\", \"It's okay, nothing special.\"),\n",
    "    (\"assistant\", \"neutral\"),\n",
    "    (\"human\", \"Worst purchase ever!\"),\n",
    "    (\"assistant\", \"negative\"),\n",
    "    (\"human\", \"{new_review}\")\n",
    "])\n",
    "\n",
    "print(\"üéØ Few-Shot Template (with examples):\")\n",
    "messages = few_shot_template.format_messages(\n",
    "    new_review=\"The interface is intuitive and fast!\"\n",
    ")\n",
    "print(f\"User review: {messages[-1].content}\")\n",
    "print(\"‚úÖ LLM will learn from examples and classify correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Chains ‚Äî Composing Complex Workflows\n",
    "\n",
    "**LCEL (LangChain Expression Language)** uses the `|` pipe operator:\n",
    "\n",
    "```python\n",
    "chain = component1 | component2 | component3\n",
    "```\n",
    "\n",
    "Think of it like Unix pipes: `cat file.txt | grep \"error\" | wc -l`\n",
    "\n",
    "**Benefits:**\n",
    "- Readable: Left-to-right data flow\n",
    "- Composable: Mix and match components\n",
    "- Async-ready: Automatic parallelization\n",
    "- Streaming: Real-time token generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# üîπ Example 1: Simple Linear Chain\n",
    "# Flow: Prompt ‚Üí LLM ‚Üí String Output\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explain {concept} in one sentence for a {audience}.\"\n",
    ")\n",
    "llm = FakeListLLM(responses=[\n",
    "    \"Machine learning is teaching computers to learn from data instead of explicit programming.\"\n",
    "])\n",
    "parser = StrOutputParser()\n",
    "\n",
    "simple_chain = prompt | llm | parser\n",
    "\n",
    "result = simple_chain.invoke({\n",
    "    \"concept\": \"machine learning\",\n",
    "    \"audience\": \"5-year-old\"\n",
    "})\n",
    "\n",
    "print(\"üîó Simple Chain Output:\")\n",
    "print(result)\n",
    "print()\n",
    "\n",
    "# üîπ Example 2: Structured Output Chain\n",
    "# Flow: Prompt ‚Üí LLM ‚Üí JSON Parser ‚Üí Validated Object\n",
    "\n",
    "class TicketAnalysis(BaseModel):\n",
    "    \"\"\"Structured analysis of a support ticket.\"\"\"\n",
    "    category: str = Field(description=\"bug, feature, question, or urgent\")\n",
    "    priority: int = Field(description=\"1-5, where 5 is highest\")\n",
    "    sentiment: str = Field(description=\"positive, neutral, or negative\")\n",
    "    key_points: list[str] = Field(description=\"main issues mentioned\")\n",
    "    suggested_response: str = Field(description=\"draft response\")\n",
    "\n",
    "structured_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Analyze this support ticket:\n",
    "\n",
    "Ticket: {ticket_text}\n",
    "\n",
    "Provide analysis in JSON format:\n",
    "{{\"category\": \"...\", \"priority\": ..., \"sentiment\": \"...\", \"key_points\": [...], \"suggested_response\": \"...\"}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "structured_llm = FakeListLLM(responses=[\n",
    "    '{\"category\": \"bug\", \"priority\": 4, \"sentiment\": \"negative\", \"key_points\": [\"export button broken\", \"happens on Chrome\"], \"suggested_response\": \"Thank you for reporting this. We are investigating the export issue on Chrome browsers and will update you within 24 hours.\"}'\n",
    "])\n",
    "\n",
    "json_parser = JsonOutputParser(pydantic_object=TicketAnalysis)\n",
    "\n",
    "structured_chain = structured_prompt | structured_llm | json_parser\n",
    "\n",
    "analysis = structured_chain.invoke({\n",
    "    \"ticket_text\": \"The export button doesn't work! I've tried 5 times on Chrome. This is blocking my work.\"\n",
    "})\n",
    "\n",
    "print(\"üìä Structured Analysis:\")\n",
    "print(f\"Category: {analysis['category']}\")\n",
    "print(f\"Priority: {analysis['priority']}/5\")\n",
    "print(f\"Sentiment: {analysis['sentiment']}\")\n",
    "print(f\"Key Points: {', '.join(analysis['key_points'])}\")\n",
    "print(f\"Response: {analysis['suggested_response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Part 3: Building a Real Support Triage System\n",
    "\n",
    "<div class=\"scenario-box\">\n",
    "<strong>üìå Scenario:</strong> You're building an intelligent ticket triage system that:\n",
    "<ol>\n",
    "<li>Accepts raw support tickets (email, chat, or web form)</li>\n",
    "<li>Classifies tickets by type and urgency</li>\n",
    "<li>Extracts key information (error codes, user IDs, steps to reproduce)</li>\n",
    "<li>Generates draft responses for common issues</li>\n",
    "<li>Routes complex cases to appropriate teams</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "### Step 1: Define the Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "from enum import Enum\n",
    "\n",
    "class TicketCategory(str, Enum):\n",
    "    BUG = \"bug\"\n",
    "    FEATURE = \"feature_request\"\n",
    "    QUESTION = \"question\"\n",
    "    BILLING = \"billing\"\n",
    "    URGENT = \"urgent\"\n",
    "\n",
    "class TicketPriority(int, Enum):\n",
    "    LOW = 1\n",
    "    MEDIUM = 2\n",
    "    HIGH = 3\n",
    "    CRITICAL = 4\n",
    "    EMERGENCY = 5\n",
    "\n",
    "class SupportTicketTriage(BaseModel):\n",
    "    \"\"\"Complete triage analysis of a support ticket.\"\"\"\n",
    "    category: TicketCategory = Field(description=\"Ticket classification\")\n",
    "    priority: TicketPriority = Field(description=\"Urgency level (1-5)\")\n",
    "    sentiment: str = Field(description=\"Customer sentiment: positive, neutral, frustrated, or angry\")\n",
    "    \n",
    "    # Extracted Information\n",
    "    error_code: Optional[str] = Field(default=None, description=\"Error code if mentioned\")\n",
    "    affected_feature: Optional[str] = Field(default=None, description=\"Product feature mentioned\")\n",
    "    user_id: Optional[str] = Field(default=None, description=\"User ID if mentioned\")\n",
    "    \n",
    "    # Analysis\n",
    "    key_issues: list[str] = Field(description=\"Main problems mentioned\")\n",
    "    reproduction_steps: Optional[list[str]] = Field(default=None, description=\"Steps to reproduce (if bug)\")\n",
    "    \n",
    "    # Recommendations\n",
    "    suggested_response: str = Field(description=\"Draft response to customer\")\n",
    "    assign_to_team: str = Field(description=\"engineering, product, billing, or support\")\n",
    "    escalate_to_human: bool = Field(description=\"Needs immediate human attention?\")\n",
    "    \n",
    "    # SLA\n",
    "    estimated_resolution_hours: int = Field(description=\"Expected time to resolve\")\n",
    "\n",
    "# Test the model\n",
    "sample_triage = SupportTicketTriage(\n",
    "    category=TicketCategory.BUG,\n",
    "    priority=TicketPriority.HIGH,\n",
    "    sentiment=\"frustrated\",\n",
    "    error_code=\"ERR_500\",\n",
    "    affected_feature=\"export\",\n",
    "    user_id=\"user_12345\",\n",
    "    key_issues=[\"export fails\", \"timeout error\"],\n",
    "    reproduction_steps=[\"Click export button\", \"Select CSV format\", \"Error appears\"],\n",
    "    suggested_response=\"We've identified the export timeout issue...\",\n",
    "    assign_to_team=\"engineering\",\n",
    "    escalate_to_human=True,\n",
    "    estimated_resolution_hours=4\n",
    ")\n",
    "\n",
    "print(\"üìã Triage Data Model:\")\n",
    "print(sample_triage.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build the Triage Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "\n",
    "# Create sophisticated prompt for ticket analysis\n",
    "triage_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an expert support ticket triage AI for CloudWave SaaS.\n",
    "\n",
    "Analyze this support ticket and provide a comprehensive triage assessment.\n",
    "\n",
    "TICKET INFORMATION:\n",
    "From: {customer_email}\n",
    "Subject: {subject}\n",
    "Message:\n",
    "{message}\n",
    "\n",
    "CUSTOMER CONTEXT:\n",
    "- Plan: {customer_plan}\n",
    "- Account Age: {account_age_days} days\n",
    "- Previous Tickets: {previous_ticket_count}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Classify the ticket (bug/feature_request/question/billing/urgent)\n",
    "2. Assign priority (1=low to 5=emergency)\n",
    "3. Assess customer sentiment\n",
    "4. Extract: error codes, affected features, user IDs\n",
    "5. List key issues and reproduction steps (if applicable)\n",
    "6. Draft a professional, helpful response\n",
    "7. Recommend team assignment (engineering/product/billing/support)\n",
    "8. Determine if human escalation is needed\n",
    "9. Estimate resolution time in hours\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "{format_instructions}\n",
    "\n",
    "Analyze now:\"\"\"\n",
    ")\n",
    "\n",
    "# Create parser with schema\n",
    "parser = JsonOutputParser(pydantic_object=SupportTicketTriage)\n",
    "\n",
    "# Add format instructions to prompt\n",
    "triage_prompt = triage_prompt.partial(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "# Create LLM (using fake for demo - replace with real LLM)\n",
    "llm = FakeListLLM(responses=[\n",
    "    '''{\n",
    "        \"category\": \"bug\",\n",
    "        \"priority\": 4,\n",
    "        \"sentiment\": \"frustrated\",\n",
    "        \"error_code\": \"ERR_TIMEOUT_500\",\n",
    "        \"affected_feature\": \"data export\",\n",
    "        \"user_id\": \"alice@example.com\",\n",
    "        \"key_issues\": [\"export times out after 30 seconds\", \"affects large datasets\", \"blocking critical workflow\"],\n",
    "        \"reproduction_steps\": [\"Navigate to Analytics dashboard\", \"Select 'Export to CSV'\", \"Choose date range > 6 months\", \"Click Export button\", \"Wait 30 seconds - timeout occurs\"],\n",
    "        \"suggested_response\": \"Thank you for reporting this, Alice. I see you're experiencing timeout issues when exporting large datasets. This is a known issue affecting datasets over 100K rows. Our engineering team is implementing a fix with chunked exports. As a temporary workaround, try exporting smaller date ranges (1-3 months). We'll update you within 24 hours with the permanent fix timeline. We apologize for the disruption to your workflow.\",\n",
    "        \"assign_to_team\": \"engineering\",\n",
    "        \"escalate_to_human\": true,\n",
    "        \"estimated_resolution_hours\": 24\n",
    "    }'''\n",
    "])\n",
    "\n",
    "# Build the triage chain\n",
    "triage_chain = triage_prompt | llm | parser\n",
    "\n",
    "print(\"‚úÖ Triage chain created!\")\n",
    "print(\"Components: Prompt ‚Üí LLM ‚Üí JSON Parser ‚Üí Validated Triage Object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test with Real-World Tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a real support ticket\n",
    "ticket_input = {\n",
    "    \"customer_email\": \"alice@techcorp.com\",\n",
    "    \"subject\": \"Urgent: Export feature broken for large datasets\",\n",
    "    \"message\": \"\"\"Hi support team,\n",
    "    \n",
    "    I'm trying to export our Q4 analytics data (about 150K rows) and the export keeps timing out after 30 seconds with error ERR_TIMEOUT_500.\n",
    "    \n",
    "    Steps I've tried:\n",
    "    1. Go to Analytics > Data Export\n",
    "    2. Select date range: Oct 1 - Dec 31\n",
    "    3. Choose CSV format\n",
    "    4. Click Export\n",
    "    5. Wait... then timeout error\n",
    "    \n",
    "    This is blocking our quarterly board presentation tomorrow. Please help ASAP!\n",
    "    \n",
    "    Thanks,\n",
    "    Alice\n",
    "    \"\"\",\n",
    "    \"customer_plan\": \"Enterprise\",\n",
    "    \"account_age_days\": 180,\n",
    "    \"previous_ticket_count\": 2\n",
    "}\n",
    "\n",
    "# Run triage\n",
    "triage_result = triage_chain.invoke(ticket_input)\n",
    "\n",
    "print(\"üé´ TICKET TRIAGE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìß From: {ticket_input['customer_email']}\")\n",
    "print(f\"üìå Subject: {ticket_input['subject']}\")\n",
    "print()\n",
    "print(\"üìä CLASSIFICATION:\")\n",
    "print(f\"  Category: {triage_result['category'].upper()}\")\n",
    "print(f\"  Priority: {triage_result['priority']}/5 ({'üî¥ HIGH' if triage_result['priority'] >= 4 else 'üü° MEDIUM'})\")\n",
    "print(f\"  Sentiment: {triage_result['sentiment']}\")\n",
    "print()\n",
    "print(\"üîç EXTRACTED INFO:\")\n",
    "print(f\"  Error Code: {triage_result['error_code']}\")\n",
    "print(f\"  Feature: {triage_result['affected_feature']}\")\n",
    "print(f\"  User: {triage_result['user_id']}\")\n",
    "print()\n",
    "print(\"üêõ KEY ISSUES:\")\n",
    "for i, issue in enumerate(triage_result['key_issues'], 1):\n",
    "    print(f\"  {i}. {issue}\")\n",
    "print()\n",
    "print(\"üîÑ REPRODUCTION STEPS:\")\n",
    "for i, step in enumerate(triage_result['reproduction_steps'], 1):\n",
    "    print(f\"  {i}. {step}\")\n",
    "print()\n",
    "print(\"üí¨ SUGGESTED RESPONSE:\")\n",
    "print(f\"  {triage_result['suggested_response']}\")\n",
    "print()\n",
    "print(\"üìã ROUTING:\")\n",
    "print(f\"  Assign to: {triage_result['assign_to_team'].upper()} team\")\n",
    "print(f\"  Escalate: {'üö® YES - Human review needed' if triage_result['escalate_to_human'] else '‚úÖ No'}\")\n",
    "print(f\"  ETA: {triage_result['estimated_resolution_hours']} hours\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Hands-On Exercises\n",
    "\n",
    "<div class=\"exercise-box\">\n",
    "<strong>üéØ Exercise 1: Build a Custom Triage Chain</strong>\n",
    "<br><br>\n",
    "Create a triage system for a <strong>different domain</strong>:\n",
    "<ul>\n",
    "<li><strong>Healthcare:</strong> Triage patient symptoms (urgent/non-urgent)</li>\n",
    "<li><strong>E-commerce:</strong> Classify product reviews (return/refund/praise)</li>\n",
    "<li><strong>HR:</strong> Screen job applications (qualified/interview/reject)</li>\n",
    "</ul>\n",
    "<br>\n",
    "<strong>Requirements:</strong>\n",
    "<ol>\n",
    "<li>Define a Pydantic model for your domain</li>\n",
    "<li>Create a prompt template with domain-specific instructions</li>\n",
    "<li>Build a chain: Prompt ‚Üí LLM ‚Üí Parser</li>\n",
    "<li>Test with 3 different inputs</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here!\n",
    "# Hint: Start by defining your Pydantic model\n",
    "\n",
    "# class YourTriageModel(BaseModel):\n",
    "#     category: str = Field(...)\n",
    "#     priority: int = Field(...)\n",
    "#     # ... add more fields\n",
    "\n",
    "# Then create your prompt, LLM, and chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise-box\">\n",
    "<strong>üéØ Exercise 2: Error Handling and Retries</strong>\n",
    "<br><br>\n",
    "Real LLM APIs can fail. Enhance the triage chain with:\n",
    "<ul>\n",
    "<li>Try/except error handling</li>\n",
    "<li>Retry logic (max 3 attempts)</li>\n",
    "<li>Fallback responses when LLM fails</li>\n",
    "<li>Logging for debugging</li>\n",
    "</ul>\n",
    "<br>\n",
    "<strong>Hint:</strong> Use <code>try/except</code> and <code>time.sleep()</code> for exponential backoff.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here!\n",
    "import time\n",
    "\n",
    "# def triage_with_retry(ticket_input, max_retries=3):\n",
    "#     for attempt in range(max_retries):\n",
    "#         try:\n",
    "#             result = triage_chain.invoke(ticket_input)\n",
    "#             return result\n",
    "#         except Exception as e:\n",
    "#             # Log error, wait, retry\n",
    "#             pass\n",
    "#     # Return fallback\n",
    "#     return {\"category\": \"unknown\", \"escalate_to_human\": True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise-box\">\n",
    "<strong>üéØ Exercise 3: Multi-Step Chain</strong>\n",
    "<br><br>\n",
    "Build a 2-step workflow:\n",
    "<ol>\n",
    "<li><strong>Step 1:</strong> Classify ticket (bug/feature/question)</li>\n",
    "<li><strong>Step 2:</strong> Based on classification, generate specialized response:\n",
    "  <ul>\n",
    "    <li>Bug ‚Üí Technical troubleshooting steps</li>\n",
    "    <li>Feature ‚Üí Product roadmap information</li>\n",
    "    <li>Question ‚Üí Knowledge base article</li>\n",
    "  </ul>\n",
    "</li>\n",
    "</ol>\n",
    "<br>\n",
    "<strong>Hint:</strong> Use <code>RunnableBranch</code> or conditional logic to route based on step 1 output.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here!\n",
    "# Step 1: Classify\n",
    "# Step 2: Route to specialized chain based on category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î Reflection Questions\n",
    "\n",
    "**Q1: When should you use temperature=0 vs 0.7 vs 1.0?**\n",
    "<details>\n",
    "<summary>Click for answer</summary>\n",
    "<ul>\n",
    "<li><strong>temperature=0:</strong> Deterministic, best for classification, extraction, structured tasks (e.g., ticket triage)</li>\n",
    "<li><strong>temperature=0.7:</strong> Balanced creativity/consistency, good for drafting responses, general Q&A</li>\n",
    "<li><strong>temperature=1.0+:</strong> Creative, good for brainstorming, content generation, multiple variations</li>\n",
    "</ul>\n",
    "<strong>Rule of thumb:</strong> Start at 0.7, lower for precision tasks, raise for creative tasks.\n",
    "</details>\n",
    "\n",
    "**Q2: How do you prevent LLM hallucinations in production?**\n",
    "<details>\n",
    "<summary>Click for answer</summary>\n",
    "<ol>\n",
    "<li><strong>Structured Outputs:</strong> Use Pydantic models + JSON parsing (constrains format)</li>\n",
    "<li><strong>Explicit Instructions:</strong> \"Only use information provided. Say 'I don't know' if uncertain.\"</li>\n",
    "<li><strong>Few-Shot Examples:</strong> Show correct behavior in prompts</li>\n",
    "<li><strong>Retrieval:</strong> Ground responses in actual data (we'll cover RAG in Week 4)</li>\n",
    "<li><strong>Human Review:</strong> For high-stakes decisions, always require human approval</li>\n",
    "</ol>\n",
    "</details>\n",
    "\n",
    "**Q3: When should you use Agents instead of Chains?**\n",
    "<details>\n",
    "<summary>Click for answer</summary>\n",
    "<strong>Use Chains when:</strong>\n",
    "<ul>\n",
    "<li>Workflow is predictable (always same steps)</li>\n",
    "<li>You want full control over execution</li>\n",
    "<li>Performance/cost is critical (chains are faster/cheaper)</li>\n",
    "</ul>\n",
    "<strong>Use Agents when:</strong>\n",
    "<ul>\n",
    "<li>LLM needs to decide which tools to use</li>\n",
    "<li>Number of steps varies based on input</li>\n",
    "<li>Problem requires reasoning and planning</li>\n",
    "</ul>\n",
    "Example: Ticket triage = Chain (fixed steps). Research task = Agent (dynamic tool use).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Week 1 Project: Email Triage System\n",
    "\n",
    "**Build a complete email triage system that:**\n",
    "\n",
    "1. **Accepts emails** with subject + body\n",
    "2. **Classifies** into categories:\n",
    "   - Spam (promotional, unsolicited)\n",
    "   - Urgent (requires immediate action)\n",
    "   - Normal (standard priority)\n",
    "   - Follow-up (needs response)\n",
    "3. **Extracts** action items (deadlines, tasks, requests)\n",
    "4. **Generates** brief summary (1-2 sentences)\n",
    "5. **Suggests** response (if applicable)\n",
    "\n",
    "**Deliverables:**\n",
    "- Pydantic model for email analysis\n",
    "- Triage chain with prompt template\n",
    "- Test with 5 different emails (include spam, urgent, normal)\n",
    "- Bonus: Add sentiment analysis\n",
    "\n",
    "**Evaluation Criteria:**\n",
    "- ‚úÖ Correct classification (compare to ground truth)\n",
    "- ‚úÖ Action items extracted accurately\n",
    "- ‚úÖ Summary is concise and relevant\n",
    "- ‚úÖ Code is clean and uses LCEL properly\n",
    "\n",
    "**Starter Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email triage project starter\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class EmailTriage(BaseModel):\n",
    "    \"\"\"Complete email analysis.\"\"\"\n",
    "    category: str = Field(description=\"spam, urgent, normal, or follow_up\")\n",
    "    priority: int = Field(description=\"1-5\")\n",
    "    # TODO: Add more fields (action_items, summary, sentiment, etc.)\n",
    "\n",
    "# TODO: Create prompt template\n",
    "# TODO: Create LLM and parser\n",
    "# TODO: Build chain\n",
    "# TODO: Test with sample emails\n",
    "\n",
    "# Sample test emails:\n",
    "test_emails = [\n",
    "    {\n",
    "        \"from\": \"boss@company.com\",\n",
    "        \"subject\": \"URGENT: Client demo tomorrow at 9am\",\n",
    "        \"body\": \"We need the slides ready by tonight. Can you send them by 8pm?\"\n",
    "    },\n",
    "    {\n",
    "        \"from\": \"marketing@spam.com\",\n",
    "        \"subject\": \"üéâ 50% OFF - Limited Time Offer!!!\",\n",
    "        \"body\": \"Buy now! Amazing deals! Click here!\"\n",
    "    },\n",
    "    # Add 3 more diverse examples\n",
    "]\n",
    "\n",
    "# Your implementation here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "**What you learned this week:**\n",
    "\n",
    "‚úÖ **LangChain fundamentals:**\n",
    "- Why LangChain > raw LLM APIs (composability, type safety, ecosystem)\n",
    "- LCEL pipe syntax: `prompt | llm | parser`\n",
    "- Prompt templates for consistency and reusability\n",
    "\n",
    "‚úÖ **Structured outputs:**\n",
    "- Pydantic models for type-safe LLM responses\n",
    "- JsonOutputParser for automatic validation\n",
    "- Handling complex nested data structures\n",
    "\n",
    "‚úÖ **Real-world application:**\n",
    "- Built production-grade support ticket triage system\n",
    "- Extracted structured information from unstructured text\n",
    "- Implemented routing logic and escalation rules\n",
    "\n",
    "‚úÖ **Best practices:**\n",
    "- Temperature settings for different use cases\n",
    "- Preventing hallucinations with constraints\n",
    "- When to use chains vs agents\n",
    "\n",
    "## üîú Next Week: Memory & Conversation\n",
    "\n",
    "In Week 2, we'll add **memory** to our chains:\n",
    "- Conversation history tracking\n",
    "- Context window management\n",
    "- Multi-turn dialogues\n",
    "- Building stateful chatbots\n",
    "\n",
    "**Preview question:** How would you modify the ticket triage system to remember previous customer interactions?\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [LCEL Guide](https://python.langchain.com/docs/expression_language/)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/)\n",
    "- [Prompt Engineering Guide](https://www.promptingguide.ai/)\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations on completing Week 1!** You're now equipped to build LLM-powered applications with LangChain. See you next week! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
